{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d3671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rtg_ws_train.py\n",
    "import numpy as np, pandas as pd, torch, torch.nn as nn, torch.nn.functional as F\n",
    "import argparse, random, sys\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import softmax\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# ------------------------ #\n",
    "# CLI Argument Parsing\n",
    "# ------------------------ #\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--device\", default=\"cpu\", help=\"cpu or cuda\")\n",
    "parser.add_argument(\"--ws_keep\", type=float, default=1.0, help=\"World Sync edge keep ratio (0~1)\")\n",
    "args, _ = parser.parse_known_args()\n",
    "DEVICE = torch.device(args.device)\n",
    "\n",
    "# ------------------------ #\n",
    "# Global Settings\n",
    "# ------------------------ #\n",
    "SEED, NEG_RATIO = 42, 2\n",
    "USER_EMB_DIM, HIDDEN_DIM = 8, 48\n",
    "BLOCK_DIM, BIAS_SCALE = 8, 1.0\n",
    "DELTA_SCALE0 = 25.0\n",
    "RANK_MARGIN = 1.0\n",
    "LR, NUM_EPOCHS = 4e-4, 80\n",
    "BATCH_NODES, NEI_L1, NEI_L2 = 8000, 10, 5\n",
    "K_SAMPLES = 3\n",
    "\n",
    "torch.manual_seed(SEED); np.random.seed(SEED); random.seed(SEED)\n",
    "if DEVICE.type == 'cuda':\n",
    "    torch.backends.cudnn.deterministic = True   \n",
    "    torch.backends.cudnn.benchmark     = False  \n",
    "\n",
    "# ------------------------ #\n",
    "# 1. Load events\n",
    "# ------------------------ #\n",
    "events = pd.read_csv(\"events.csv\", usecols=[\"visitorid\",\"timestamp\",\"event\",\"itemid\"])\n",
    "events = events.sort_values([\"visitorid\", \"timestamp\"]).reset_index(drop=True)\n",
    "events[\"block_type\"] = events.event.map({\"view\":1, \"addtocart\":2, \"transaction\":3})\n",
    "gap = events.groupby(\"visitorid\")[\"timestamp\"].diff().fillna(0)\n",
    "events[\"session_id\"] = (gap > 3600000).astype(int).groupby(events.visitorid).cumsum()\n",
    "events[\"items\"] = events.itemid\n",
    "events[\"t_bucket\"] = ((events.timestamp - events.timestamp.min()) // (30*60*1000)).astype(\"int32\")\n",
    "\n",
    "# ------------------------ #\n",
    "# 2. Blocks → Edges\n",
    "# ------------------------ #\n",
    "def build_blocks(df):\n",
    "    blks = df.groupby([\"visitorid\", \"session_id\", \"timestamp\", \"block_type\"], as_index=False)\\\n",
    "             .agg({\"items\": \"first\"}).rename(columns={\"timestamp\": \"start_time\"})\n",
    "    blks[\"next_bt\"] = blks.groupby([\"visitorid\", \"session_id\"]).block_type.shift(-1)\n",
    "    blks[\"label\"] = (blks.next_bt == 3).astype(int)\n",
    "    return blks.dropna(subset=[\"next_bt\"])\n",
    "\n",
    "blocks = build_blocks(events)\n",
    "s_start = blocks.groupby([\"visitorid\",\"session_id\"]).start_time.min()\n",
    "c1, c2 = s_start.quantile([.70, .85])\n",
    "split = blocks.set_index([\"visitorid\",\"session_id\"])\n",
    "tr_blk = split.loc[s_start <= c1].reset_index()\n",
    "va_blk = split.loc[(s_start > c1) & (s_start <= c2)].reset_index()\n",
    "te_blk = split.loc[s_start > c2].reset_index()\n",
    "\n",
    "def blks2edges(blks):\n",
    "    blks[\"prev_bt\"] = blks.groupby([\"visitorid\",\"session_id\"]).block_type.shift(1).fillna(0).astype(int)\n",
    "    return blks.explode(\"items\", ignore_index=True).rename(columns={\"visitorid\":\"user\", \"items\":\"item\"})\\\n",
    "               [[\"user\", \"item\", \"block_type\", \"prev_bt\", \"label\"]]\n",
    "\n",
    "edge_tr_full = blks2edges(tr_blk)\n",
    "edge_val = blks2edges(va_blk)\n",
    "edge_test = blks2edges(te_blk)\n",
    "\n",
    "# ------------------------ #\n",
    "# 3. Undersample\n",
    "# ------------------------ #\n",
    "pos = edge_tr_full[edge_tr_full.label == 1]\n",
    "neg = edge_tr_full[edge_tr_full.label == 0].sample(len(pos)*NEG_RATIO, random_state=SEED)\n",
    "edge_train = pd.concat([pos, neg]).sample(frac=1, random_state=SEED)\n",
    "\n",
    "# ------------------------ #\n",
    "# 4. Attr & Mapping\n",
    "# ------------------------ #\n",
    "def onehot(x): return np.eye(4)[x]\n",
    "def attr(df): return np.hstack([onehot(df.prev_bt), onehot(df.block_type)])\n",
    "\n",
    "tr_attr_base = torch.tensor(attr(edge_train), dtype=torch.float)\n",
    "va_attr_base = attr(edge_val)\n",
    "te_attr_base = attr(edge_test)\n",
    "\n",
    "uid2idx, it2idx = {}, {}\n",
    "add_u = lambda u: uid2idx.setdefault(u, len(uid2idx))\n",
    "add_i = lambda i: it2idx.setdefault(i, len(uid2idx) + len(it2idx))\n",
    "ui_src = edge_train.user.map(add_u).to_numpy(np.int32)\n",
    "ui_dst = edge_train.item.map(add_i).to_numpy(np.int32)\n",
    "unk_u = add_u(\"__UNK__\"); unk_it = add_i(\"__UNK_IT__\")\n",
    "\n",
    "# ------------------------ #\n",
    "# 5. World Sync Edges\n",
    "# ------------------------ #\n",
    "ws_src, ws_dst = [], []\n",
    "rng = np.random.default_rng(SEED)\n",
    "for (_, _), users in events.groupby([\"t_bucket\", \"itemid\"])[\"visitorid\"].unique().items():\n",
    "    if len(users) < 2: continue\n",
    "    for u in users:\n",
    "        others = [v for v in users if v != u]\n",
    "        for v in rng.choice(others, min(K_SAMPLES, len(others)), replace=False):\n",
    "            ws_src.append(add_u(u)); ws_dst.append(add_u(v))\n",
    "ws_src, ws_dst = np.array(ws_src), np.array(ws_dst)\n",
    "if args.ws_keep < 1.0:\n",
    "    keep = rng.choice(len(ws_src), int(len(ws_src)*args.ws_keep), replace=False)\n",
    "    ws_src, ws_dst = ws_src[keep], ws_dst[keep]\n",
    "\n",
    "edge_src = np.concatenate([ui_src, ws_src])\n",
    "edge_dst = np.concatenate([ui_dst, ws_dst])\n",
    "edge_user = np.concatenate([ui_src, ws_src])\n",
    "edge_attr = torch.cat([\n",
    "    tr_attr_base,\n",
    "    torch.zeros((len(ws_src), 8), dtype=tr_attr_base.dtype, device=tr_attr_base.device)\n",
    "])\n",
    "prev_bt = torch.tensor(np.concatenate([edge_train.prev_bt.values, np.zeros(len(ws_src))]), dtype=torch.long)\n",
    "curr_bt = torch.tensor(np.concatenate([edge_train.block_type.values, np.zeros(len(ws_src))]), dtype=torch.long)\n",
    "\n",
    "# ------------------------ #\n",
    "# 6. Graph\n",
    "# ------------------------ #\n",
    "num_nodes = max(edge_src.max(), edge_dst.max()) + 1\n",
    "graph = Data(x=torch.zeros((num_nodes, 1)),\n",
    "             edge_index=torch.tensor([edge_src, edge_dst]),\n",
    "             edge_attr=edge_attr,\n",
    "             edge_user=torch.tensor(edge_user),\n",
    "             prev_bt=prev_bt,\n",
    "             curr_bt=curr_bt)\n",
    "\n",
    "# ------------------------ #\n",
    "# 7. Model\n",
    "# ------------------------ #\n",
    "class EAGAT(MessagePassing):\n",
    "    def __init__(self, in_c, out_c, e_c):\n",
    "        super().__init__('add')\n",
    "        self.lin_n = nn.Linear(in_c, out_c, False)\n",
    "        self.lin_e = nn.Linear(e_c, out_c, False)\n",
    "        self.att = nn.Parameter(torch.randn(1, 3*out_c))\n",
    "    def forward(self, x, ei, ea): return self.propagate(ei, x=self.lin_n(x), edge_attr=self.lin_e(ea))\n",
    "    def message(self, x_j, x_i, edge_attr, index):\n",
    "        a = torch.cat([x_i, x_j, edge_attr], 1) @ self.att.T\n",
    "        a = F.leaky_relu(a.squeeze(-1), 0.2)\n",
    "        a = softmax(a, index)\n",
    "        return x_j * a.unsqueeze(-1)\n",
    "\n",
    "class RTG(nn.Module):\n",
    "    def __init__(self, num_users):\n",
    "        super().__init__()\n",
    "        self.block_emb = nn.Embedding(4, BLOCK_DIM, padding_idx=0)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.delta_scale = nn.Parameter(torch.tensor(DELTA_SCALE0))\n",
    "        self.bias_scale = nn.Parameter(torch.tensor(BIAS_SCALE))\n",
    "        self.g1 = EAGAT(1, HIDDEN_DIM, 9)\n",
    "        self.g2 = EAGAT(HIDDEN_DIM, HIDDEN_DIM, 9)\n",
    "        self.edge_mlp = nn.Sequential(nn.Linear(HIDDEN_DIM*2 + 9, HIDDEN_DIM), nn.ReLU(), nn.Linear(HIDDEN_DIM, 1))\n",
    "    def _delta_hat(self, prev_bt, curr_bt, user_id):\n",
    "        e1 = self.block_emb(prev_bt)\n",
    "        e2 = self.block_emb(curr_bt)\n",
    "        dist = torch.norm(e1 - e2, p=2, dim=1)\n",
    "        user_b = self.user_bias(user_id).squeeze(-1)\n",
    "        return self.delta_scale * dist + self.bias_scale * user_b\n",
    "    def _edge_full(self, ea, prev_bt, curr_bt, user_id):\n",
    "        Δ = self._delta_hat(prev_bt, curr_bt, user_id).unsqueeze(-1)\n",
    "        return torch.cat([ea, Δ], 1)\n",
    "    def forward(self, d):\n",
    "        ea = self._edge_full(d.edge_attr, d.prev_bt, d.curr_bt, d.edge_user)\n",
    "        h = self.g1(d.x, d.edge_index, ea)\n",
    "        return self.g2(h, d.edge_index, ea)\n",
    "    def edge_pred(self, h, ei, ea, prev_bt, curr_bt, user_id):\n",
    "        full_ea = self._edge_full(ea, prev_bt, curr_bt, user_id)\n",
    "        u, v = ei\n",
    "        return self.edge_mlp(torch.cat([h[u], h[v], full_ea], 1)).view(-1)\n",
    "\n",
    "# ------------------------ #\n",
    "# 8. Ranking Loss\n",
    "# ------------------------ #\n",
    "def delta_ranking_loss(model, edge_df, device):\n",
    "    code = edge_df.prev_bt.values * 4 + edge_df.block_type.values\n",
    "    code = torch.tensor(code, device=device)\n",
    "    prev = torch.tensor(edge_df.prev_bt.values, device=device)\n",
    "    curr = torch.tensor(edge_df.block_type.values, device=device)\n",
    "    user = torch.tensor(edge_df.user.map(uid2idx).fillna(unk_u).to_numpy(np.int64), device=device)\n",
    "    delta = model._delta_hat(prev, curr, user)\n",
    "    loss = 0.0\n",
    "    for hi, lo in [((1,3),(1,1))]:\n",
    "        hi_code = hi[0]*4 + hi[1]; lo_code = lo[0]*4 + lo[1]\n",
    "        mask_hi, mask_lo = (code==hi_code), (code==lo_code)\n",
    "        if mask_hi.sum()==0 or mask_lo.sum()==0: continue\n",
    "        Δ_hi = delta[mask_hi].mean(); Δ_lo = delta[mask_lo].mean()\n",
    "        loss += F.relu(Δ_lo - Δ_hi + RANK_MARGIN)\n",
    "    return loss\n",
    "\n",
    "# ------------------------ #\n",
    "# 9. Train\n",
    "# ------------------------ #\n",
    "# 9. Train\n",
    "model = RTG(len(uid2idx)).to(DEVICE)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "crit = lambda log, y: F.binary_cross_entropy_with_logits(\n",
    "    log, y, pos_weight=torch.tensor(np.sqrt(NEG_RATIO), device=DEVICE))\n",
    "\n",
    "# ── NEW: cache full prev / curr tensors on DEVICE ───────────────\n",
    "prev_bt_all = torch.tensor(edge_train.prev_bt.values, dtype=torch.long, device=DEVICE)\n",
    "curr_bt_all = torch.tensor(edge_train.block_type.values, dtype=torch.long, device=DEVICE)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "ui_edges = torch.tensor([ui_src, ui_dst], device=DEVICE)\n",
    "ui_user  = torch.tensor(ui_src, device=DEVICE)\n",
    "ui_attr  = tr_attr_base.to(DEVICE)\n",
    "ui_y     = torch.tensor(edge_train.label.values, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "loader = NeighborLoader(graph, [NEI_L1, NEI_L2], batch_size=BATCH_NODES, shuffle=True)\n",
    "for ep in range(1, NUM_EPOCHS + 1):\n",
    "    model.train(); tot = 0\n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        batch = batch.to(DEVICE); opt.zero_grad()\n",
    "        h = model(batch)\n",
    "\n",
    "        g2l = -torch.ones(num_nodes, dtype=torch.long, device=DEVICE)\n",
    "        g2l[batch.n_id] = torch.arange(batch.num_nodes, device=DEVICE)\n",
    "        m = (g2l[ui_edges[0]] >= 0) & (g2l[ui_edges[1]] >= 0)\n",
    "        if not m.any(): continue\n",
    "        ei = torch.stack([g2l[ui_edges[0][m]], g2l[ui_edges[1][m]]], 0)\n",
    "\n",
    "        # ── OLD ─────────────────────────────────────────────\n",
    "        # prev_bt = torch.tensor(edge_train.prev_bt.values[m], ...)\n",
    "        # curr_bt = torch.tensor(edge_train.block_type.values[m], ...)\n",
    "        # ── NEW: just slice the cached tensors ─────────────\n",
    "        prev_bt = prev_bt_all[m]\n",
    "        curr_bt = curr_bt_all[m]\n",
    "        # ──────────────────────────────────────────────────\n",
    "\n",
    "        log  = model.edge_pred(h, ei, ui_attr[m], prev_bt, curr_bt, ui_user[m])\n",
    "        loss = crit(log, ui_y[m])\n",
    "        if batch_idx == 0:          # one global ranking penalty per epoch\n",
    "            rank_penalty = 0.1 * delta_ranking_loss(model, edge_train, DEVICE)\n",
    "            loss = loss + rank_penalty\n",
    "        loss.backward(); opt.step()\n",
    "        tot += loss.item() * m.sum().item()\n",
    "    print(f\"Ep {ep:3d}  loss={tot/len(ui_src):.4f}\")\n",
    "\n",
    "\n",
    "# ------------------------ #\n",
    "# 10. Eval\n",
    "# ------------------------ #\n",
    "model.eval()\n",
    "h_all = torch.zeros((num_nodes, HIDDEN_DIM), device=DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in NeighborLoader(graph, [-1], batch_size=4000):\n",
    "        batch = batch.to(DEVICE)\n",
    "        h_all[batch.n_id] = model(batch)\n",
    "\n",
    "\n",
    "def eval_set(df, attr_np, thresholds):\n",
    "    u = torch.tensor(df.user.map(uid2idx).fillna(unk_u).to_numpy(np.int64),\n",
    "                     device=DEVICE)\n",
    "    i = torch.tensor(df.item.map(it2idx).fillna(unk_it).to_numpy(np.int64),\n",
    "                     device=DEVICE)\n",
    "    ei = torch.stack([u, i], 0)\n",
    "    ea = torch.tensor(attr_np, dtype=torch.float32, device=DEVICE)\n",
    "    eu = u\n",
    "    prev_bt = torch.tensor(df.prev_bt.values, dtype=torch.long, device=DEVICE)\n",
    "    curr_bt = torch.tensor(df.block_type.values, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prob = torch.sigmoid(model.edge_pred(h_all, ei, ea, prev_bt, curr_bt, eu)).numpy()\n",
    "    y = df.label.values\n",
    "    best = None\n",
    "    for th in thresholds:\n",
    "        pred = prob > th\n",
    "        f1 = f1_score(y, pred, zero_division=0)\n",
    "        if not best or f1 > best[0]:\n",
    "            best = (f1, th, precision_score(y, pred), recall_score(y, pred))\n",
    "    return best\n",
    "\n",
    "# Threshold search\n",
    "thresholds = np.linspace(0.05, 0.95, 19)\n",
    "val = eval_set(edge_val, va_attr_base, thresholds)\n",
    "test = eval_set(edge_test, te_attr_base, [val[1]])\n",
    "\n",
    "# Output\n",
    "print(f\"[Val ] F1 {val[0]:.4f}  P {val[2]:.4f} R {val[3]:.4f} thr {val[1]:.2f}\")\n",
    "print(f\"[Test] F1 {test[0]:.4f} P {test[2]:.4f} R {test[3]:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
